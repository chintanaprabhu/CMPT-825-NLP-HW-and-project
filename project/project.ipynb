{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic Comment Classification - Kaggle Competition\n",
    "\n",
    "## Motivation\n",
    "- The threat of abuse and harassment online means that many people stop expressing themselves and give up on seeking different opinions. Platforms struggle to effectively facilitate conversations, leading many communities to limit or completely shut down user comments.\n",
    "- The task we are planning to work on is a multi label toxic comment classification problem from a Kaggle Competition by Jigsaw\n",
    "- We experimented and compared multiple models such as Logistic Regression, LSTM and Text CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "- The dataset is provided by Kaggle, containing a large number of Wikipedia comments which have been labeled by human raters for toxic behavior. The types of toxicity are:\n",
    "    \n",
    "    - toxic\n",
    "    - severe_toxic\n",
    "    - obscene\n",
    "    - threat\n",
    "    - insult\n",
    "    - identity_hate\n",
    "\n",
    "- We are provided with train, test and a sample submission file\n",
    "### Here's how the data looks like: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# loading the data\n",
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "df_test_labels = pd.read_csv('data/test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  toxic  severe_toxic  obscene  threat  insult  \\\n",
       "0  00001cee341fdb12     -1            -1       -1      -1      -1   \n",
       "1  0000247867823ef7     -1            -1       -1      -1      -1   \n",
       "2  00013b17ad220c46     -1            -1       -1      -1      -1   \n",
       "3  00017563c3f7919a     -1            -1       -1      -1      -1   \n",
       "4  00017695ad8997eb     -1            -1       -1      -1      -1   \n",
       "\n",
       "   identity_hate  \n",
       "0             -1  \n",
       "1             -1  \n",
       "2             -1  \n",
       "3             -1  \n",
       "4             -1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "Our approach to the problems is structured as follows:\n",
    "1. EDA\n",
    "2. Data Preprocessing\n",
    "3. Models\n",
    "4. Evaluation\n",
    "\n",
    "### 1. EDA\n",
    "- EDA notebook can be found here - [EDA](EDA.ipynb)\n",
    "\n",
    "- Through EDA we found out that the dataset is highly skewed where 9.6% of the 160K comments are classified as toxic and rest as non-toxic.\n",
    "\n",
    "- A severe toxic comment is always toxic and other classes seem to be a subset of toxic barring a few exceptions.\n",
    "\n",
    "#### 1.1. Word Length Distribution\n",
    "- Below plots show the total word count frequency distribution across train and test data after preprocessing.\n",
    "<img src=\"Images/word_len_dist.png\" alt=\"Word Length Distribution\" style=\"width: 700px;\"/>\n",
    "\n",
    "#### 1.2. Category Distribution\n",
    "- From the category distribution venn diagram and the bar plot below we can see that the toxicity is not evenly spread out across classes i.e. classes are imbalanced.\n",
    "- Also we can see that the three major labels are:\n",
    "    - toxic\n",
    "    - obscene\n",
    "    - insult\n",
    "\n",
    "<img src=\"Images/label_dist.png\" alt=\"Category Distribution 1\" style=\"width: 600px;\"/>\n",
    "<img src=\"Images/label_dist_2.png\" alt=\"Category Distribution 2\" style=\"width: 300px;\"/>\n",
    "\n",
    "#### 1.3. Category Correlation\n",
    "- The category correlation plot below shows label combinations that are frequent.\n",
    "- We can deduce that `toxic` is coming in all combination.\n",
    "- Also, the number of comments for each combination drops exponentially.\n",
    "<img src=\"Images/label_correlation.png\" alt=\"Category Correlation\" style=\"width: 500px;\"/>\n",
    "\n",
    "#### 1.4. Category Correlation Venn diagrams\n",
    "- Below venn diagrams show combinations for all labels with `toxic`\n",
    "##### 1.4.1. Venn diagram for Toxic and severe_toxic comments\n",
    "<img src=\"Images/venn_toxic_severe.png\" alt=\"Toxic and severe_toxic comments\" style=\"width: 300px;\"/>\n",
    "\n",
    "##### 1.4.2. Venn diagram for Toxic Toxic and obscene comments\n",
    "<img src=\"Images/venn_toxic_obscene.png\" alt=\"Toxic and obscene comments\" style=\"width: 300px;\"/>\n",
    "\n",
    "##### 1.4.3. Venn diagram for Toxic Toxic and insult comments\n",
    "<img src=\"Images/venn_toxic_insult.png\" alt=\"Toxic and insult comments\" style=\"width: 300px;\"/>\n",
    "\n",
    "##### 1.4.4. Venn diagram for Toxic Toxic and threat comments\n",
    "<img src=\"Images/venn_toxic_threat.png\" alt=\"Toxic and threat comments\" style=\"width: 300px;\"/>\n",
    "\n",
    "##### 1.4.5. Venn diagram for Toxic Toxic and identity_hate comments\n",
    "<img src=\"Images/venn_toxic_identity_hate.png\" alt=\"Toxic and identity_hate comments\" style=\"width: 300px;\"/>\n",
    "\n",
    "##### 1.4.6. Venn diagram for Toxic Toxic, insult and obscene comments\n",
    "- We can see from the plot below that `toxic` labelled comments are highly correlated with `obscene` and `insult`.\n",
    "<img src=\"Images/venn_toxic_insult_obsene.png\" alt=\"Toxic, insult and obscene comments\" style=\"width: 300px;\"/>\n",
    "\n",
    "### 2. Data Preprocessing\n",
    "\n",
    "- Notebook with an example can be found here - [Data Cleaning](prepocessing.ipynb)\n",
    "- We have created a dictionary of apostrophe words like `you're` that converts it into its raw form `you are`.\n",
    "- We are using Tweet Tokenizer and WordNet Lemmatizer from NLTK\n",
    "- Also, we use stopwords provided form NLTK\n",
    "- Below is how we preprocess the text\n",
    "<img src=\"Images/data_cleaning.png\" alt=\"Preprocessing\" style=\"width: 400px;\"/>\n",
    "\n",
    "### 3. Models\n",
    "#### 3.1. Logistic Regression\n",
    "\n",
    "- We have used logistic regression as the baseline model for this task.\n",
    "- We are vectorizing the word from the dataset using TF-IDF and feeding this matrix into logistic regression. This method portrays the importance of a word to a document in a corpus. \n",
    "- For classification problems whole data set is used for feature extraction. We will lose information if we use only training \n",
    "data. \n",
    "- Classifier converges at 200 iterations.\n",
    "- Inverse of regularization strength is set to 1 for stronger regularization.\n",
    "- The weights are balanced to adjust inversely proportional to output label frequencies in the input data.\n",
    "\n",
    "<img src=\"Images/logistic_regression.png\" alt=\"Logistic Regression\" style=\"width: 300px;\"/>\n",
    "\n",
    "#### 3.2. Two Stacked Bidirectional LSTM\n",
    "\n",
    "- We have trained two stacked bidirectional LSTM networks for this task.\n",
    "- The comment text is cleaned and preprocessed before feeding to the embedding layer.\n",
    "- We have combined two pre-trained word embeddings trained on the Common Crawl dataset. They can be downloaded here - [crawl-300d-2M.vec.zip](https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip) and [glove.840B.300d.txt](http://nlp.stanford.edu/data/glove.840B.300d.zip)\n",
    "- We used Keras Tokenizer class to create text sequences and padded them to get equal length inputs with maximum length of 100.\n",
    "- Training of the model is done for 4 epochs only.\n",
    "- During training, we have also used Learning Rate Scheduling.  \n",
    "\n",
    "<img src=\"Images/lstm.png\" alt=\"Two Stacked Bidirectional LSTM\" style=\"width: 400px;\"/>\n",
    "\n",
    "#### 3.3. Text CNN\n",
    "\n",
    "- Our CNN model is inspired from Yoo Kimâ€™s CNN model - [Convolutional Neural Networks for Sentence Classification](https://arxiv.org/abs/1408.5882)\n",
    "- We use pre-trained word embeddings from FastText. They can be downloaded here - [crawl-300d-2M.vec.zip](https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip)\n",
    "- The word vectors are fine tuned while training.\n",
    "- We use convolutions with 32 filters of sizes 1, 2, 3 and 5 at different layers to extract features from the comment followed by max pooling layer\n",
    "- Finally we concat the features together and pass them through  fully connected layers to get predictions.\n",
    "- BCE loss for training. \n",
    "- Model is trained using ADAM optimizer with the default learning rate of 0.001 that keras has. The model converges after 3-4 epochs.\n",
    "\n",
    "<img src=\"Images/textCNN.png\" alt=\"Text CNN\" style=\"width: 600px;\"/>\n",
    "\n",
    "### 4. Evaluation\n",
    "The predictions are evaluated on the mean column-wise ROC AUC. In other words, the score is the average of the individual AUCs of each predicted column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Setup\n",
    "\n",
    "Each model is trained based on a train validation data split. After training each model, the model is used for prediction on the test set provided by Kaggle and the generated submission file is submitted to Kaggle to calculate the public and private leaderboard AUC scores.\n",
    "\n",
    "Code for each model can be found here:\n",
    "- For Logistic Regression - `/Log_reg`\n",
    "- For Two Stacked Bidirectional LSTM - `/LSTM`\n",
    "- For Text CNN - `/TextCNN`\n",
    "\n",
    "Each model can be run from their respective files in their corresponding folder:\n",
    "- To run Logistic Regression - `python3 Log_reg/log_regression.py`\n",
    "- To run Two Stacked Bidirectional LSTM - `python3 LSTM/LSTM.py`\n",
    "- To run TextCNN - `python3 TextCNN/textCNN.py`\n",
    "\n",
    "Submission file for each model can be found in their respective folders:\n",
    "- For Logistic Regression - `Log_reg/logReg_submission.csv`\n",
    "- For Two Stacked Bidirectional LSTM - `LSTM/LSTM_submission.csv`\n",
    "- For Text CNN - `TextCNN/textCNN_submission.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "Loss plot for Logistic Regression \n",
    "<img src=\"Images/log_reg_loss.png\" alt=\"Results\" style=\"width: 500px;\"/>\n",
    "\n",
    "Loss plot for LSTM\n",
    "<img src=\"Images/lstm_loss.png\" alt=\"Results\" style=\"width: 500px;\"/>\n",
    "\n",
    "Loss plot for TextCNN\n",
    "<img src=\"Images/textCNN_loss.png\" alt=\"Results\" style=\"width: 500px;\"/>\n",
    "\n",
    "Following table shows results for all three methods\n",
    "<img src=\"Images/results.png\" alt=\"Results\" style=\"width: 500px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the Results\n",
    "\n",
    "- Based on our results TextCNN seems to have predicted better than Logistic Regression and LSTM.\n",
    "- Using pre-trained embbeddings lead to faster convergence and due to using those embeddings, minor modifications to LSTM and CNN do not defer the predictions by major margins.\n",
    "- Bettering the data preprocessing may improve the performance of all the models. For our approach a text like `Thanks for uploading Image:Wonju.jpg.` after cleaning looks like this `thank upload image wonju jpg` Here `wonju` and `jpg` do not add any information to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "- Using pre-trained word embeddings lead to faster convergence.\n",
    "- The toxicity is not evenly spread out across classes hence class imbalance problems.\n",
    "- Ensembling methods generally give higher leaderboard score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work\n",
    "\n",
    "- Exploring other models such as BERT, Two layer  Bidirectional GRU, etc\n",
    "- We found that one of the top 10 Kagglers used Train and test-time augmentation (TTA) using translations to German, French and Spanish and back to English and got improved performance.\n",
    "- Stacking and Blending models might improve the performance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
