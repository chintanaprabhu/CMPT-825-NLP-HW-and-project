{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chunker: default program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from default import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the default solution on dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1027/1027 [00:03<00:00, 304.95it/s]\n"
     ]
    }
   ],
   "source": [
    "chunker = LSTMTagger(os.path.join('data', 'train.txt.gz'), os.path.join('data', 'chunker'), '.tar')\n",
    "decoder_output = chunker.decode('data/input/dev.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the default output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 23663 tokens with 11896 phrases; found: 12077 phrases; correct: 9383.\n",
      "accuracy:  87.41%; (non-O)\n",
      "accuracy:  88.41%; precision:  77.69%; recall:  78.88%; FB1:  78.28\n",
      "             ADJP: precision:  45.00%; recall:  19.91%; FB1:  27.61  100\n",
      "             ADVP: precision:  71.80%; recall:  47.99%; FB1:  57.53  266\n",
      "            CONJP: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "             INTJ: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "               NP: precision:  76.63%; recall:  82.36%; FB1:  79.39  6704\n",
      "               PP: precision:  91.33%; recall:  88.45%; FB1:  89.86  2364\n",
      "              PRT: precision:  70.27%; recall:  57.78%; FB1:  63.41  37\n",
      "             SBAR: precision:  77.62%; recall:  46.84%; FB1:  58.42  143\n",
      "               VP: precision:  69.59%; recall:  74.39%; FB1:  71.91  2463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(77.69313571251139, 78.87525218560862, 78.27973136445169)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_output = [ output for sent in decoder_output for output in sent ]\n",
    "import conlleval\n",
    "true_seqs = []\n",
    "with open(os.path.join('data','reference','dev.out')) as r:\n",
    "    for sent in conlleval.read_file(r):\n",
    "        true_seqs += sent.split()\n",
    "conlleval.evaluate(true_seqs, flat_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "We have implemented:<br>\n",
    "Option 1: Baseline model by concatenating character vectors. Filename: `chunker_baseline.py` and `default_baseline.py`<br>\n",
    "Option 2: Concatenating hidden layer of RNN having character vectors as input. Filename: `chunker.py` and `default.py`<br>\n",
    "\n",
    "#### Function for preparing character vector \n",
    "The `prepare_character_vectors(sentence, width=100)` method creates a character level representation of the word\n",
    "    - v1 is a one-hot vector for the first character of the word.\n",
    "    - v2 is a vector where the index of all the inbetween characters have the count of that character in the word\n",
    "    - v3 is a one-hot vector for the last character of the word.\n",
    "```\n",
    "def prepare_character_vectors(sentence, width=100):\n",
    "    character_vectors = []\n",
    "    for word in sentence:\n",
    "        v1 = torch.zeros(width)\n",
    "        v2 = torch.zeros(width)\n",
    "        v3 = torch.zeros(width)\n",
    "\n",
    "        if word is not '[UNK]':\n",
    "            v1[string.printable.find(word[0])] = 1\n",
    "\n",
    "            unique_chars = list(set(word[1:-1]))\n",
    "            for unique_char in unique_chars:\n",
    "                v2[string.printable.find(unique_char)] = word.count(unique_char)\n",
    "\n",
    "            v3[string.printable.find(word[-1])] = 1\n",
    "\n",
    "        character_vectors.append(torch.cat((v1, v2, v3), 0))\n",
    "    return torch.stack(character_vectors)\n",
    "```\n",
    "\n",
    "#### RNN Network for Option 2\n",
    "For the Option 2 we have additionally implemented a separate RNN that takes in the character vector representation and outputs its hidden state which is concatenated with the word embeddings before passing through the LSTM\n",
    "\n",
    "In the first step, a hidden state is seeded as a matrix of zeros, so that it can be fed into the RNN cell together with the first input in the sequence. The hidden state and the input data will be multiplied with weight matrices. The result of these multiplications will then be passed through an activation function(such as a tanh function) to introduce non-linearity. This gives us the hidden state of the RNN cell. We do not compute the output for the cell since it's not needed.\n",
    "\n",
    "`hidden_t = tanh(weight_hidden ∗ hidden_t−1 + weight_input ∗ input_t)`\n",
    "\n",
    "```\n",
    "class CharacterRNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(CharacterRNN, self).__init__()\n",
    "\n",
    "        self.Wih = nn.Linear(input_dim, hidden_dim)\n",
    "        self.Wio = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, input_seq, hidden):\n",
    "        # combined = torch.cat((input_seq, hidden), 2)\n",
    "        hidden = self.tanh(self.Wih(input_seq) + self.Wio(hidden))\n",
    "\n",
    "        return hidden\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Do some analysis of the results. What ideas did you try? What worked and what did not?\n",
    "\n",
    "Option 1 gave us a score of `77.2100` on dev<br>\n",
    "For Option 2 we experimented with various sizes for the RNN's hidden layer. A size of 64 gave us the best score of `78.2797` on dev<br>\n",
    "\n",
    "Below are their individual runs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Option 1 - Concatenating character vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 28/1027 [00:00<00:03, 276.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LSTMTaggerModel(\n",
      "  (word_embeddings): Embedding(9675, 128)\n",
      "  (lstm): LSTM(428, 64)\n",
      "  (hidden2tag): Linear(in_features=64, out_features=22, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1027/1027 [00:03<00:00, 313.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 23663 tokens with 11896 phrases; found: 11961 phrases; correct: 9210.\n",
      "accuracy:  86.86%; (non-O)\n",
      "accuracy:  87.85%; precision:  77.00%; recall:  77.42%; FB1:  77.21\n",
      "             ADJP: precision:  42.11%; recall:  17.70%; FB1:  24.92  95\n",
      "             ADVP: precision:  69.74%; recall:  47.49%; FB1:  56.50  271\n",
      "            CONJP: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "             INTJ: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "               NP: precision:  75.36%; recall:  80.66%; FB1:  77.92  6676\n",
      "               PP: precision:  91.10%; recall:  88.49%; FB1:  89.78  2371\n",
      "              PRT: precision:  69.23%; recall:  60.00%; FB1:  64.29  39\n",
      "             SBAR: precision:  84.80%; recall:  44.73%; FB1:  58.56  125\n",
      "               VP: precision:  69.51%; recall:  71.92%; FB1:  70.69  2384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(77.00025081514924, 77.42098184263618, 77.21004317391123)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from default_baseline import *\n",
    "import os\n",
    "\n",
    "chunker = LSTMTagger(os.path.join('data', 'train.txt.gz'), os.path.join('data', 'chunker_baseline'), '.tar')\n",
    "print(\"Model:\", chunker.model)\n",
    "decoder_output = chunker.decode('data/input/dev.txt')\n",
    "\n",
    "flat_output = [ output for sent in decoder_output for output in sent ]\n",
    "import conlleval\n",
    "true_seqs = []\n",
    "with open(os.path.join('data','reference','dev.out')) as r:\n",
    "    for sent in conlleval.read_file(r):\n",
    "        true_seqs += sent.split()\n",
    "conlleval.evaluate(true_seqs, flat_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2 Concatenating hidden layer of RNN having character vectors as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 29/1027 [00:00<00:03, 284.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LSTMTaggerModel(\n",
      "  (word_embeddings): Embedding(9675, 128)\n",
      "  (character_rnn): CharacterRNN(\n",
      "    (Wih): Linear(in_features=300, out_features=64, bias=True)\n",
      "    (Wio): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (tanh): Tanh()\n",
      "  )\n",
      "  (lstm): LSTM(192, 64)\n",
      "  (hidden2tag): Linear(in_features=64, out_features=22, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1027/1027 [00:03<00:00, 271.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 23663 tokens with 11896 phrases; found: 12077 phrases; correct: 9383.\n",
      "accuracy:  87.41%; (non-O)\n",
      "accuracy:  88.41%; precision:  77.69%; recall:  78.88%; FB1:  78.28\n",
      "             ADJP: precision:  45.00%; recall:  19.91%; FB1:  27.61  100\n",
      "             ADVP: precision:  71.80%; recall:  47.99%; FB1:  57.53  266\n",
      "            CONJP: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "             INTJ: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "               NP: precision:  76.63%; recall:  82.36%; FB1:  79.39  6704\n",
      "               PP: precision:  91.33%; recall:  88.45%; FB1:  89.86  2364\n",
      "              PRT: precision:  70.27%; recall:  57.78%; FB1:  63.41  37\n",
      "             SBAR: precision:  77.62%; recall:  46.84%; FB1:  58.42  143\n",
      "               VP: precision:  69.59%; recall:  74.39%; FB1:  71.91  2463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(77.69313571251139, 78.87525218560862, 78.27973136445169)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from default import *\n",
    "import os\n",
    "\n",
    "chunker = LSTMTagger(os.path.join('data', 'train.txt.gz'), os.path.join('data', 'chunker'), '.tar')\n",
    "print(\"Model:\", chunker.model)\n",
    "decoder_output = chunker.decode('data/input/dev.txt')\n",
    "\n",
    "flat_output = [ output for sent in decoder_output for output in sent ]\n",
    "import conlleval\n",
    "true_seqs = []\n",
    "with open(os.path.join('data','reference','dev.out')) as r:\n",
    "    for sent in conlleval.read_file(r):\n",
    "        true_seqs += sent.split()\n",
    "conlleval.evaluate(true_seqs, flat_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
